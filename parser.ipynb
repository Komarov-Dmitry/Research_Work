{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://hh.ru/oauth/authorize?response_type=code&client_id=YOUR_CLIENT_ID&redirect_uri=YOUR_REDIRECT_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://hh.ru/oauth/authorize?response_type=code&client_id=GF7CCTJ1VEVD3C69BHDR2IB425DLQR1B7NIBMF88DO8G6E42LE8K314L2Q48NGT2&redirect_uri=https://t.me/bl3sk_soul'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://hh.ru/oauth/authorize?response_type=code&client_id=' + client_id + '&redirect_uri=' + redirect_url\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Собираем данные для позиции: Разработчик\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обработка вакансий для позиции 'Разработчик': 100%|██████████| 1007/1007 [15:17<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Собираем данные для позиции: Аналитик\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обработка вакансий для позиции 'Аналитик': 100%|██████████| 1201/1201 [17:56<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Собираем данные для позиции: Инженер\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обработка вакансий для позиции 'Инженер': 100%|██████████| 1290/1290 [19:17<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Собираем данные для позиции: Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обработка вакансий для позиции 'Data': 100%|██████████| 595/595 [08:47<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Собираем данные для позиции: Прграммист\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обработка вакансий для позиции 'Прграммист': 100%|██████████| 972/972 [13:49<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Собираем данные для позиции: Системный администратор\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обработка вакансий для позиции 'Системный администратор': 100%|██████████| 1532/1532 [22:17<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Собираем данные для позиции: Тестировщик\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обработка вакансий для позиции 'Тестировщик': 100%|██████████| 756/756 [11:30<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Собираем данные для позиции: DevOps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обработка вакансий для позиции 'DevOps': 100%|██████████| 532/532 [07:40<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Собираем данные для позиции: Machine Learning Engineer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обработка вакансий для позиции 'Machine Learning Engineer': 100%|██████████| 43/43 [00:38<00:00,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Данные успешно сохранены в 'vacancies_data_with_salary.json'.\n",
      "Количество сохраненных вакансий: 7928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# import requests\n",
    "# import time\n",
    "# import json\n",
    "# from tqdm import tqdm  # Для отображения прогресса\n",
    "\n",
    "# # Список IT-позиций\n",
    "# it_positions = ['Разработчик', 'Аналитик', 'Инженер', 'Data', 'Прграммист', 'Системный администратор', 'Тестировщик', 'DevOps', 'Machine Learning Engineer']\n",
    "\n",
    "# # Получение списка вакансий по запросу\n",
    "# def get_vacancies_by_position(position, max_pages=70):\n",
    "#     \"\"\"\n",
    "#     Получает список вакансий для указанной позиции с указанным количеством страниц.\n",
    "#     max_pages по умолчанию 50 для увеличения объема данных.\n",
    "#     \"\"\"\n",
    "#     url = \"https://api.hh.ru/vacancies\"\n",
    "#     vacancies = []\n",
    "#     for page in range(max_pages):\n",
    "#         params = {\n",
    "#             \"text\": position,\n",
    "#             \"per_page\": 100,  # Максимальное количество вакансий на странице\n",
    "#             \"page\": page,\n",
    "#         }\n",
    "#         response = requests.get(url, params=params)\n",
    "#         response.raise_for_status()\n",
    "#         data = response.json()\n",
    "#         # Отфильтровываем только вакансии с указанной зарплатой\n",
    "#         vacancies.extend([item for item in data[\"items\"] if item.get(\"salary\") is not None])\n",
    "#         if page >= data[\"pages\"] - 1:\n",
    "#             break  # Если страниц больше нет, выходим из цикла\n",
    "#         time.sleep(0.5)  # Задержка для соблюдения лимитов\n",
    "#     return vacancies\n",
    "\n",
    "# # Получение полной информации по вакансии\n",
    "# def get_vacancy_details(vacancy_id):\n",
    "#     \"\"\"\n",
    "#     Получает полную информацию по вакансии, включая ключевые навыки и другие параметры.\n",
    "#     \"\"\"\n",
    "#     url = f\"https://api.hh.ru/vacancies/{vacancy_id}\"\n",
    "#     response = requests.get(url)\n",
    "#     response.raise_for_status()\n",
    "#     vacancy = response.json()\n",
    "#     return {\n",
    "#         \"id\": vacancy.get(\"id\"),\n",
    "#         \"name\": vacancy.get(\"name\"),\n",
    "#         \"area\": vacancy.get(\"area\", {}).get(\"name\"),\n",
    "#         \"salary\": vacancy.get(\"salary\"),\n",
    "#         \"published_at\": vacancy.get(\"published_at\"),\n",
    "#         \"schedule\": vacancy.get(\"schedule\", {}).get(\"name\"),\n",
    "#         \"professional_roles\": [role[\"name\"] for role in vacancy.get(\"professional_roles\", [])],\n",
    "#         \"experience\": vacancy.get(\"experience\", {}).get(\"name\"),\n",
    "#         \"employment\": vacancy.get(\"employment\", {}).get(\"name\"),\n",
    "#         \"key_skills\": [skill[\"name\"] for skill in vacancy.get(\"key_skills\", [])]\n",
    "#     }\n",
    "\n",
    "# # Основная функция\n",
    "# def main():\n",
    "#     all_data = []\n",
    "#     for position in it_positions:\n",
    "#         print(f\"Собираем данные для позиции: {position}\")\n",
    "#         try:\n",
    "#             vacancies = get_vacancies_by_position(position)\n",
    "#             for vacancy in tqdm(vacancies, desc=f\"Обработка вакансий для позиции '{position}'\"):\n",
    "#                 vacancy_id = vacancy[\"id\"]\n",
    "#                 try:\n",
    "#                     vacancy_details = get_vacancy_details(vacancy_id)\n",
    "#                     all_data.append(vacancy_details)\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Ошибка при получении данных вакансии {vacancy_id}: {e}\")\n",
    "#                 time.sleep(0.5)  # Задержка для API\n",
    "#         except Exception as e:\n",
    "#             print(f\"Ошибка для позиции {position}: {e}\")\n",
    "    \n",
    "#     # Сохранение данных в JSON\n",
    "#     with open(\"vacancies_data_with_salary.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "#         json.dump(all_data, json_file, ensure_ascii=False, indent=4)\n",
    "    \n",
    "#     # Вывод количества сохраненных вакансий\n",
    "#     print(f\"\\nДанные успешно сохранены в 'vacancies_data_with_salary.json'.\")\n",
    "#     print(f\"Количество сохраненных вакансий: {len(all_data)}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Парсинг резюме по позиции: Разработчик\n",
      "Парсинг резюме по позиции: Аналитик\n",
      "Парсинг резюме по позиции: Инженер\n",
      "Парсинг резюме по позиции: Data\n",
      "Парсинг резюме по позиции: Программист\n",
      "Парсинг резюме по позиции: Системный администратор\n",
      "Парсинг резюме по позиции: Тестировщик\n",
      "Парсинг резюме по позиции: DevOps\n",
      "Парсинг резюме по позиции: Machine Learning Engineer\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# Список позиций для поиска\n",
    "it_positions = ['Разработчик', 'Аналитик', 'Инженер', 'Data', 'Программист', \n",
    "                'Системный администратор', 'Тестировщик', 'DevOps', 'Machine Learning Engineer']\n",
    "\n",
    "# Функция для получения HTML-страницы\n",
    "def get_html(url):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36'\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Функция для парсинга одной страницы с резюме\n",
    "def parse_resume_page(html):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    resumes = []\n",
    "    for item in soup.find_all('div', class_='resume-search-item__name'):\n",
    "        name = item.get_text(strip=True)\n",
    "        link = item.find('a')['href']\n",
    "        resumes.append({'name': name, 'link': link})\n",
    "    return resumes\n",
    "\n",
    "# Основной парсер\n",
    "def parse_hh(it_positions, max_pages=5):\n",
    "    base_url = \"https://hh.ru/search/resume\"\n",
    "    all_resumes = []\n",
    "\n",
    "    for position in it_positions:\n",
    "        print(f\"Парсинг резюме по позиции: {position}\")\n",
    "        for page in range(max_pages):\n",
    "            params = {\n",
    "                'text': position,\n",
    "                'page': page\n",
    "            }\n",
    "            url = f\"{base_url}?text={position}&page={page}\"\n",
    "            html = get_html(url)\n",
    "            if html:\n",
    "                resumes = parse_resume_page(html)\n",
    "                if not resumes:  # Если нет резюме, выходим из цикла\n",
    "                    break\n",
    "                all_resumes.extend(resumes)\n",
    "                print(f\"Страница {page + 1}: найдено {len(resumes)} резюме\")\n",
    "            time.sleep(2)  # Пауза, чтобы избежать блокировки\n",
    "\n",
    "    return all_resumes\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    resumes = parse_hh(it_positions)\n",
    "    for resume in resumes:\n",
    "        print(f\"Имя: {resume['name']}, Ссылка: {resume['link']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
